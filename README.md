# Big Data Projects
This repository showcases my **Big Data** projects, covering **data engineering, machine learning, and real-time processing** using technologies like **Apache Spark, Hive, PostgreSQL, MongoDB, and more**. It also demonstrates my experience working with platforms such as **Hadoop, Azure Databricks, MongoDB Atlas, and Docker**.

## Projects
[Hive PostgreSQL ETL](https://github.com/lilhuss26/BigData_Projects/tree/main/Hive-PostgreSQL-ETL):  Data warehousing using Hadoop Hive and an ETL pipeline in Python for PostgreSQL.
[LSTM Stream Prediction](https://github.com/lilhuss26/BigData_Projects/tree/main/LSTM-PySpark-Stream-Prediction): LSTM-based time-series sales prediction with real-time data processing using `PySpark` Streaming.
[Spark MLlib Mongodb](https://github.com/lilhuss26/BigData_Projects/tree/main/Spark-MLlib-Mongodb):Deploying a machine learning model using `PySpark` and MongoDB collections

## Technologies
+ **SQL:** Used for processing and storing data across different database engines (**PostgreSQL, Hive, MongoDB**).

+ **PySpark:** Utilized various PySpark libraries:
  - **MLlib**: For training and deploying ML models.
  - **SQL**: For data manipulation and preparation.
  - **Streaming**: For real-time data processing.

+ **Python Database Connectores:** Like `pymongo`, `pyhive` and `psycopg2` to connect and interact with database engines, this was useful with **ETL** and **models deploying**

+ **Cloud:** 
    - ***Azure Databricks*** A powerful cloud-based PySpark engine with essential dependencies and resources.
    - ***MongoDB Atlas*** Cloud storage for MongoDB collections, providing easy accessibility and scalability.

+ **Docker:** Leveraged pre-built images for ***database engines*** and ***big data frameworks***. Solving  dependency management and environment isolation.
